{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da2618d",
   "metadata": {},
   "outputs": [],
   "source": [
    "TÉCNICA | VENTAJAS BRISCAS | DESVENTAJAS\n",
    "Monte Carlo | Maneja incertidumbre | Requiere más recursos\n",
    "Redes Neuronales | Aprende patrones complejos | Necesita grandes datasets\n",
    "Minimax | Óptimo teóricamente | No escala bien\n",
    "Monte Carlo | Simula múltiples escenarios | Puede ser lento\n",
    "Q-learning | Aprende de la experiencia | Requiere exploración"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38b1f9f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tu mano: [10 de espadas, 1 de bastos, 5 de espadas]\n",
      "Vida actual: 4 de copas\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 129\u001b[39m\n\u001b[32m    126\u001b[39m juego.repartir()\n\u001b[32m    128\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m10\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m129\u001b[39m     ganador = \u001b[43mjuego\u001b[49m\u001b[43m.\u001b[49m\u001b[43mjugar_turno\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    130\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mGanador de la mano: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mjuego.jugadores[ganador].nombre\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    131\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mPuntos acumulados: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mdict\u001b[39m(juego.puntos)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 43\u001b[39m, in \u001b[36mBriscasGame.jugar_turno\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     41\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.jugadores)):\n\u001b[32m     42\u001b[39m     jugador = \u001b[38;5;28mself\u001b[39m.jugadores[\u001b[38;5;28mself\u001b[39m.turno % \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.jugadores)]\n\u001b[32m---> \u001b[39m\u001b[32m43\u001b[39m     carta = \u001b[43mjugador\u001b[49m\u001b[43m.\u001b[49m\u001b[43mseleccionar_carta\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     44\u001b[39m     \u001b[38;5;28mself\u001b[39m.mano_actual.append(carta)\n\u001b[32m     45\u001b[39m     \u001b[38;5;28mself\u001b[39m.turno += \u001b[32m1\u001b[39m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 80\u001b[39m, in \u001b[36mAgenteMCTS.seleccionar_carta\u001b[39m\u001b[34m(self, juego)\u001b[39m\n\u001b[32m     78\u001b[39m puntos = \u001b[32m0\u001b[39m\n\u001b[32m     79\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(simulaciones):\n\u001b[32m---> \u001b[39m\u001b[32m80\u001b[39m     copia_juego = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msimular_jugada\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcarta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjuego\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     81\u001b[39m     puntos += copia_juego.puntos[\u001b[38;5;28mself\u001b[39m]\n\u001b[32m     83\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m puntos > mejores_puntos:\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 100\u001b[39m, in \u001b[36mAgenteMCTS.simular_jugada\u001b[39m\u001b[34m(self, carta_inicial, juego_actual)\u001b[39m\n\u001b[32m     98\u001b[39m jugador_actual = copia_juego.jugadores[copia_juego.turno % \u001b[38;5;28mlen\u001b[39m(copia_juego.jugadores)]\n\u001b[32m     99\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m jugador_actual == \u001b[38;5;28mself\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m100\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m    101\u001b[39m carta = random.choice(jugador_actual.mano)\n\u001b[32m    102\u001b[39m jugador_actual.mano.remove(carta)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import random\n",
    "from collections import defaultdict\n",
    "\n",
    "VALORES = {\n",
    "    1: 11, 3: 10, 12: 4, 11: 3, 10: 2,\n",
    "    7: 0, 6: 0, 5: 0, 4: 0, 2: 0\n",
    "}\n",
    "\n",
    "PALOS = ['oros', 'copas', 'espadas', 'bastos']\n",
    "\n",
    "class Carta:\n",
    "    def __init__(self, valor, palo):\n",
    "        self.valor = valor\n",
    "        self.palo = palo\n",
    "        self.puntos = VALORES[valor]\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"{self.valor} de {self.palo}\"\n",
    "\n",
    "class BriscasGame:\n",
    "    def __init__(self, jugadores):\n",
    "        self.jugadores = jugadores\n",
    "        self.mazo = self._crear_mazo()\n",
    "        self.vida = None\n",
    "        self.mano_actual = []\n",
    "        self.puntos = defaultdict(int)\n",
    "        self.turno = 0\n",
    "        \n",
    "    def _crear_mazo(self):\n",
    "        return [Carta(v, p) for v in VALORES for p in PALOS for _ in range(2)]\n",
    "    \n",
    "    def repartir(self):\n",
    "        random.shuffle(self.mazo)\n",
    "        self.vida = self.mazo.pop()\n",
    "        for _ in range(3):\n",
    "            for jugador in self.jugadores:\n",
    "                jugador.recibir_carta(self.mazo.pop())\n",
    "    \n",
    "    def jugar_turno(self):\n",
    "        jugadas = []\n",
    "        for _ in range(len(self.jugadores)):\n",
    "            jugador = self.jugadores[self.turno % len(self.jugadores)]\n",
    "            carta = jugador.seleccionar_carta(self)\n",
    "            self.mano_actual.append(carta)\n",
    "            self.turno += 1\n",
    "        \n",
    "        ganador = self.determinar_ganador_mano()\n",
    "        self.puntos[ganador] += sum(c.puntos for c in self.mano_actual)\n",
    "        self.mano_actual = []\n",
    "        return ganador\n",
    "    \n",
    "    def determinar_ganador_mano(self):\n",
    "        lider_palo = self.mano_actual[0].palo\n",
    "        cartas_vida = [c for c in self.mano_actual if c.palo == self.vida.palo]\n",
    "        \n",
    "        if cartas_vida:\n",
    "            return max(enumerate(cartas_vida), \n",
    "                      key=lambda x: (x[1].valor, x[0]))[0]\n",
    "        else:\n",
    "            return max(enumerate([c for c in self.mano_actual \n",
    "                                if c.palo == lider_palo]),\n",
    "                      key=lambda x: (x[1].valor, x[0]))[0]\n",
    "\n",
    "class AgenteMCTS:\n",
    "    def __init__(self, nombre):\n",
    "        self.nombre = nombre\n",
    "        self.mano = []\n",
    "    \n",
    "    def recibir_carta(self, carta):\n",
    "        self.mano.append(carta)\n",
    "    \n",
    "    def seleccionar_carta(self, juego):\n",
    "        simulaciones = 100\n",
    "        mejores_puntos = -1\n",
    "        mejor_carta = None\n",
    "        \n",
    "        for carta in self.mano:\n",
    "            puntos = 0\n",
    "            for _ in range(simulaciones):\n",
    "                copia_juego = self.simular_jugada(carta, juego)\n",
    "                puntos += copia_juego.puntos[self]\n",
    "            \n",
    "            if puntos > mejores_puntos:\n",
    "                mejores_puntos = puntos\n",
    "                mejor_carta = carta\n",
    "        \n",
    "        self.mano.remove(mejor_carta)\n",
    "        return mejor_carta\n",
    "    \n",
    "    def simular_jugada(self, carta_inicial, juego_actual):\n",
    "        # Implementación de simulación Monte Carlo\n",
    "        copia_juego = BriscasGame([self] + juego_actual.jugadores[1:])\n",
    "        copia_juego.vida = juego_actual.vida\n",
    "        copia_juego.mano_actual = [carta_inicial]\n",
    "        \n",
    "        # Simular jugadas aleatorias restantes\n",
    "        while len(copia_juego.mano_actual) < len(copia_juego.jugadores):\n",
    "            jugador_actual = copia_juego.jugadores[copia_juego.turno % len(copia_juego.jugadores)]\n",
    "            if jugador_actual == self:\n",
    "                continue\n",
    "            carta = random.choice(jugador_actual.mano)\n",
    "            jugador_actual.mano.remove(carta)\n",
    "            copia_juego.mano_actual.append(carta)\n",
    "        \n",
    "        return copia_juego\n",
    "\n",
    "class AgenteHumano:\n",
    "    def __init__(self, nombre):\n",
    "        self.nombre = nombre\n",
    "        self.mano = []\n",
    "    \n",
    "    def recibir_carta(self, carta):\n",
    "        self.mano.append(carta)\n",
    "    \n",
    "    def seleccionar_carta(self, juego):\n",
    "        print(f\"\\nTu mano: {self.mano}\")\n",
    "        print(f\"Vida actual: {juego.vida}\")\n",
    "        idx = int(input(\"Selecciona carta (0-2): \"))\n",
    "        return self.mano.pop(idx)\n",
    "\n",
    "# Ejemplo de uso\n",
    "if __name__ == \"__main__\":\n",
    "    humano = AgenteHumano(\"Jugador 1\")\n",
    "    ia = AgenteMCTS(\"IA Brisquera\")\n",
    "    juego = BriscasGame([humano, ia])\n",
    "    juego.repartir()\n",
    "    \n",
    "    for _ in range(10):\n",
    "        ganador = juego.jugar_turno()\n",
    "        print(f\"\\nGanador de la mano: {juego.jugadores[ganador].nombre}\")\n",
    "        print(f\"Puntos acumulados: {dict(juego.puntos)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "431b7960",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgenteMejorado(AgenteMCTS):\n",
    "    def simular_jugada(self, carta_inicial, juego_actual):\n",
    "        # Implementar poda alfa-beta o funciones de evaluación heurísticas\n",
    "        if self._es_ultima_mano():\n",
    "            return self._evaluar_mano_final()\n",
    "        # Añadir lógica de aprendizaje por refuerzo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2f64f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "modelo = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(128, activation='relu', input_shape=(estado_size,)),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "modelo.compile(optimizer='adam', \n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
